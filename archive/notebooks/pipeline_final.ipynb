{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-29T17:12:05.999327Z",
     "start_time": "2024-04-29T17:12:05.932372Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "import ast\n",
    "\n",
    "from event_loop.activity_boundaries import ActivityBoundariesClassifier\n",
    "from event_loop.activity_type import ActivityTypeClassifier\n",
    "from event_loop.event_activity import EventActivityAssignment\n",
    "from event_loop.preprocessing.dataframe import *\n",
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "df_train_in = pd.read_csv('../data_v3/hr_extended_features.csv', converters={\"MessageAttributes\": ast.literal_eval})\n",
    "# This is the Interleaved Data Set for our pipeline\n",
    "df_il_in = pd.read_csv('../data/HR-INTERLEAVED/R1/R1.csv', converters={\"MessageAttributes\": ast.literal_eval})\n",
    "\n",
    "# Load start and end events from ground truth data.\n",
    "# Tag according frames in interleaved data for testing\n",
    "df_gt = pd.read_csv(\"../data_v3/hr_ground_truth.csv\")\n",
    "\n",
    "start_indices = df_gt[\"start\"].tolist()\n",
    "end_indices = df_gt[\"actual_end\"].tolist()\n",
    "\n",
    "df_train = pre_process(df_train_in)\n",
    "df_test = pre_process(df_il_in)\n",
    "\n",
    "df_train = assign_sequence_number(df_train)\n",
    "\n",
    "df_test[\"ActivityAction\"] = df_test[\"frame.number\"].apply(lambda x: \"Activity Start\" if x in start_indices else\n",
    "(\"Activity End\" if x in end_indices else \"NoAction\"))\n",
    "\n",
    "df_train = mark_start_end(df_train)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-29T12:21:03.741174Z",
     "start_time": "2024-04-29T12:20:52.169385Z"
    }
   },
   "id": "dfc3003b42163a70"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "activity_boundaries_classifier = ActivityBoundariesClassifier(df_train, None)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-29T12:22:32.775524Z",
     "start_time": "2024-04-29T12:22:16.515145Z"
    }
   },
   "id": "7c7d5d697eea2f09"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Event Loop"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9c948705b16d83d6"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "records = df_il_in.to_dict(\"records\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-29T12:22:38.623522Z",
     "start_time": "2024-04-29T12:22:38.151738Z"
    }
   },
   "id": "f16b836c38a7a564"
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GenerateJobApplicationActivity\n",
      "ResumeReviewActivity\n",
      "GenerateJobApplicationActivity\n",
      "ResumeReviewActivity\n",
      "GenerateJobApplicationActivity\n",
      "ResumeReviewActivity\n",
      "ScheduleAnInterviewActivityCall\n",
      "GenerateJobApplicationActivity\n",
      "ResumeReviewActivity\n",
      "PerformAnInterviewCall\n",
      "GenerateJobApplicationActivity\n",
      "ResumeReviewActivity\n",
      "GenerateJobApplicationActivity\n",
      "ResumeReviewActivity\n",
      "ScheduleAnInterviewActivityCall\n",
      "GenerateJobApplicationActivity\n",
      "PerformAnInterviewCall\n",
      "ResumeReviewActivity\n",
      "ScheduleAnInterviewActivityCall\n",
      "GenerateJobApplicationActivity\n",
      "ScheduleAnInterviewMeeting\n",
      "ResumeReviewActivity\n",
      "NO MATCH RES 16032\n",
      "GenerateJobApplicationActivity\n",
      "PerformAnInterviewCall\n",
      "PerformAnInterviewMeeting\n",
      "ScheduleAnInterviewActivityCall\n",
      "ScheduleAnInterviewMeeting\n",
      "GenerateJobApplicationActivity\n",
      "ResumeReviewActivity\n",
      "PerformAnInterviewCall\n",
      "PerformAnInterviewMeeting\n",
      "ScheduleAnInterviewActivityCall\n",
      "ResumeReviewActivity\n",
      "ScheduleAnInterviewMeeting\n",
      "ContractProposal\n",
      "PerformAnInterviewCall\n",
      "PerformAnInterviewMeeting\n"
     ]
    }
   ],
   "source": [
    "from event_loop.event_activity import *\n",
    "%autoreload 2\n",
    "\n",
    "from event_loop.preprocessing.event import keep_event\n",
    "import time\n",
    "from event_loop.stack import *\n",
    "from event_loop.event import Event\n",
    "\n",
    "\n",
    "EVENT_LOOP_CUTOFF_NO_ACTION = 3\n",
    "EVENT_LOOP_CUTOFF_END_EVENT = 3\n",
    "ENTROPY_THRESHOLD = 0.4 #0.5\n",
    "MAX_WINDOW_SIZE = 10\n",
    "VERBOSE = False\n",
    "SETTING = \"HR\"\n",
    "\n",
    "# init variables\n",
    "event_buffer: list[Event] = []\n",
    "attribute_buffer: list[dict] = []\n",
    "stacks: list[Stack] = []\n",
    "stacks_out: list[Stack] = []\n",
    "event_loop_index = 0\n",
    "\n",
    "\n",
    "# TODO Change config to something like this:\n",
    "config_dict = {\n",
    "    \"PTP\": {\n",
    "        \"1to1\" : [\"applicant_id\", \"activity_id\"],\n",
    "        \"1toN\": [\"mail_id\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "HR_ATTRIBUTES = [\"applicant_id\", \"activity_id\"]\n",
    "PTP_ATTRIBUTES = [\"sale_order_id\", \"sale_order_line_id\",\"purchase_requisition_id\",\"purchase_requisition_line_id\",]\n",
    "\n",
    "\n",
    "#activity_model_data = get_activity_model_data(MAX_WINDOW_SIZE)\n",
    "\n",
    "\n",
    "processing_times = []\n",
    "buffer_sizes = []\n",
    "\n",
    "for i, event_data in enumerate(records):\n",
    "    buffer_sizes.append(sum([len(stack) for stack in stacks]))\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Filter Event Stream\n",
    "    if not keep_event(event_data):\n",
    "        # skip event in loop\n",
    "        continue\n",
    "        \n",
    "    # count every not filtered event for event loop index\n",
    "    event_loop_index += 1\n",
    "    \n",
    "    # Extract Features and generate Event Object\n",
    "    event = Event(event_data, event_loop_index, event_buffer, SETTING)\n",
    "    event_buffer.append(event)\n",
    "    \n",
    "    activity_boundaries_classifier.classify_event(event) \n",
    "    activity_action = event.activity_action\n",
    "    \n",
    "    \n",
    "        # Activity Matching\n",
    "    if activity_action == \"Activity Start\": \n",
    "        stacks.append(Stack(SETTING,event))\n",
    "        \n",
    "    if activity_action == \"NoAction\": \n",
    "        if len(stacks) == 1: \n",
    "            stacks[0].append_event(event)\n",
    "        elif event.origin_request_frame: \n",
    "            idx = search_stack_for_request_frame(event.origin_request_frame, stacks)\n",
    "            stacks[idx].append_event(event)\n",
    "        else: \n",
    "            # Check attributes of each stack\n",
    "            \n",
    "            # we can filter out stacks that already have attributes different to the event\n",
    "            exclude_indices =  event_activity_model.exclude_stacks_by_attribute(stacks, event)\n",
    "    \n",
    "            stack_index:int = event_activity_model.check_stack_attributes(stacks, event, exclude_indices)\n",
    "                    \n",
    "            if stack_index == -1:        \n",
    "                stack_index = event_activity_model.assign_to_sequence(event, stacks, 4, exclude_indices)\n",
    "            \n",
    "            # for elements that are not matchable based on 2 sequences we fall back to stream index\n",
    "            if stack_index == -1: \n",
    "                stack_index = search_stream_index(stacks, event, exclude_indices)    \n",
    "            \n",
    "            # fallback - no match add to first stack\n",
    "            if stack_index == -1:\n",
    "                res = next((i for i in range(len(stacks)) if i not in exclude_indices and stacks[i].confidence),-1)\n",
    "                stack_index = res\n",
    "                \n",
    "            stacks[stack_index].append_event(event)\n",
    "            \n",
    "            \n",
    "    if activity_action == \"Activity End\":\n",
    "        stack_index = search_stack_for_request_frame(event.origin_request_frame, stacks)\n",
    "        stacks[stack_index].append_event(event)\n",
    "        \n",
    "        if event.confidence: \n",
    "            if len(stacks) > 1: \n",
    "                stack = stacks.pop(stack_index)\n",
    "                label = activity_type_classifier.classify_stack(stack)\n",
    "                stack.label = label \n",
    "                stacks_out.append(stack)\n",
    "                \n",
    "            else: \n",
    "                event.confidence = False\n",
    "                    \n",
    "    # Loop through all currently open stacks\n",
    "    for idx, stack in enumerate(stacks):\n",
    "        last_event = stack[-1]\n",
    "        # check for non-confident \"No Action\" Classifications. These could be \"Activity End\" Instead\n",
    "        if not last_event.confidence and last_event.activity_action == \"NoAction\":\n",
    "            # If a stack has not been continued for N event loops \n",
    "            if event_loop_index - last_event.event_loop_index > EVENT_LOOP_CUTOFF_NO_ACTION:\n",
    "                label = activity_type_classifier.classify_stack(stack)\n",
    "                stack.label = label \n",
    "                stacks.pop(idx)\n",
    "                stacks_out.append(stack)\n",
    "               \n",
    "                \n",
    "    for idx, stack in enumerate(stacks): \n",
    "        last_event = stack.events[-1]\n",
    "        if not last_event.confidence and last_event.activity_action == \"Activity End\": \n",
    "            if event_loop_index - last_event.event_loop_index > EVENT_LOOP_CUTOFF_END_EVENT: \n",
    "                label = activity_type_classifier.classify_stack(stack)\n",
    "                stack.label = label            \n",
    "                # we are now sure to pop the stack.\n",
    "                stacks.pop(idx)\n",
    "                stacks_out.append(stack)  \n",
    "            \n",
    "                \n",
    "    end_time = time.time()\n",
    "    processing_times.append(end_time - start_time)\n",
    "    \n",
    "for stack in stacks: \n",
    "    label = activity_type_classifier.classify_stack(stack)\n",
    "    stack.label = label      \n",
    "    stacks_out.append(stack)        "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-29T16:53:29.727516Z",
     "start_time": "2024-04-29T16:53:29.329254Z"
    }
   },
   "id": "3259bc6e0274fba4"
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of matching start and end sequences: 1.0\n",
      "Overall matching accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# create Evaluation Data Frame\n",
    "start = [stack[0].frame_number for stack in stacks_out]\n",
    "end = [stack[-1].frame_number for stack in stacks_out]\n",
    "label = [stack.label for stack in stacks_out]\n",
    "case_id = [stack.case_id[\"id\"] for stack in stacks_out]\n",
    "res_df = pd.DataFrame({\"start_pred\":start, \"end_pred\":end,\"label\": label, \"case_id\": case_id})\n",
    "\n",
    "eval_df = df_gt[[\"start\", \"actual_end\",\"activity_name\",\"bp_id\"]].merge(res_df,how=\"left\", left_on =\"start\", right_on = \"start_pred\").fillna(-1)\n",
    "eval_df[\"pred_true\"] = eval_df[\"actual_end\"] == eval_df[\"end_pred\"]\n",
    "eval_df[\"label_true\"] = eval_df[\"activity_name\"] == eval_df[\"label\"]\n",
    "print(f\"Accuracy of matching start and end sequences: {eval_df['pred_true'].mean()}\")\n",
    "\n",
    "bp_id_norm = eval_df[\"bp_id\"] - eval_df[\"bp_id\"].min() +1\n",
    "\n",
    "eval_df[\"case_id_true\"] = bp_id_norm == eval_df[\"case_id\"]\n",
    "print(f\"Overall matching accuracy: {0.5 + eval_df['pred_true'].mean()/2}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-29T17:19:58.181885Z",
     "start_time": "2024-04-29T17:19:58.107327Z"
    }
   },
   "id": "58da0b1fe4b3eb66"
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "  Activity End       1.00      1.00      1.00        37\n",
      "Activity Start       1.00      1.00      1.00        37\n",
      "      NoAction       1.00      1.00      1.00      1239\n",
      "\n",
      "      accuracy                           1.00      1313\n",
      "     macro avg       1.00      1.00      1.00      1313\n",
      "  weighted avg       1.00      1.00      1.00      1313\n"
     ]
    }
   ],
   "source": [
    "# We evaluate the Activity Type Classification on a per-event Basis\n",
    "from event_loop.activity_boundaries import extract_labels\n",
    "\n",
    "test_labels = extract_labels(df_test[\"ActivityAction\"])\n",
    "# Create a Dataframe with all events and their frame numbers\n",
    "df_aa_test = pd.DataFrame(df_test[[\"frame.number\", \"ActivityAction\"]])\n",
    "# Set type of every event to no action \n",
    "df_aa_test[\"ActivityAction\"] = \"NoAction\"\n",
    "# Merge Predicted end events by frame number\n",
    "df_aa_test.loc[df_aa_test[\"frame.number\"].isin(eval_df[\"end_pred\"]), \"ActivityAction\"] = \"Activity End\"\n",
    "# Merge predicted start events by frame number\n",
    "df_aa_test.loc[df_aa_test[\"frame.number\"].isin(eval_df[\"start_pred\"]), \"ActivityAction\"] = \"Activity Start\"\n",
    "print(classification_report(test_labels, df_aa_test[\"ActivityAction\"]))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-29T17:22:52.202337Z",
     "start_time": "2024-04-29T17:22:52.141514Z"
    }
   },
   "id": "d3c782592b291587"
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 precision    recall  f1-score   support\n",
      "\n",
      "               ContractProposal       1.00      1.00      1.00         1\n",
      " GenerateJobApplicationActivity       1.00      1.00      1.00        10\n",
      "         PerformAnInterviewCall       1.00      1.00      1.00         5\n",
      "      PerformAnInterviewMeeting       1.00      1.00      1.00         3\n",
      "           ResumeReviewActivity       1.00      1.00      1.00        10\n",
      "ScheduleAnInterviewActivityCall       1.00      1.00      1.00         5\n",
      "     ScheduleAnInterviewMeeting       1.00      1.00      1.00         3\n",
      "\n",
      "                       accuracy                           1.00        37\n",
      "                      macro avg       1.00      1.00      1.00        37\n",
      "                   weighted avg       1.00      1.00      1.00        37\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(eval_df[\"activity_name\"], eval_df[\"label\"]))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-29T17:22:57.119524Z",
     "start_time": "2024-04-29T17:22:57.053245Z"
    }
   },
   "id": "491b73b322fdccbf"
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 precision    recall  f1-score   support\n",
      "\n",
      "               ContractProposal       1.00      1.00      1.00         1\n",
      " GenerateJobApplicationActivity       1.00      1.00      1.00        10\n",
      "         PerformAnInterviewCall       1.00      1.00      1.00         5\n",
      "      PerformAnInterviewMeeting       1.00      1.00      1.00         3\n",
      "           ResumeReviewActivity       1.00      1.00      1.00        10\n",
      "ScheduleAnInterviewActivityCall       1.00      1.00      1.00         5\n",
      "     ScheduleAnInterviewMeeting       1.00      1.00      1.00         3\n",
      "\n",
      "                       accuracy                           1.00        37\n",
      "                      macro avg       1.00      1.00      1.00        37\n",
      "                   weighted avg       1.00      1.00      1.00        37\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(eval_df[\"activity_name\"], eval_df[\"label\"]))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-29T17:22:57.941728Z",
     "start_time": "2024-04-29T17:22:57.894527Z"
    }
   },
   "id": "2560db5c116ea7d1"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
