{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-12-01T13:25:44.445549Z",
     "start_time": "2023-12-01T13:25:40.600936Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/seb/git/master_thesis/nw_event_abstraction/venv/lib/python3.9/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2.0 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from keras.src.utils import to_categorical\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from numpy.lib.stride_tricks import sliding_window_view\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from keras.src.layers import LSTM\n",
    "from keras import Sequential\n",
    "from keras.src.layers import Embedding\n",
    "from keras.src.layers import Dense\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras import Input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "train_r1 = pd.read_csv('../data/Train/R1/R1.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-01T13:25:48.657905Z",
     "start_time": "2023-12-01T13:25:44.446396Z"
    }
   },
   "id": "ec74857609cc5e9d"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Mark start event of each BusinessActivity Instance\n",
    "train_r1[\"activityStart\"] = train_r1.groupby([\"BusinessActivity\",\"InstanceNumber\",]).cumcount()==0\n",
    "# Mark end event of each Business Activity Instance\n",
    "train_r1[\"activityEnd\"] = train_r1.groupby([\"BusinessActivity\",\"InstanceNumber\",]).cumcount(ascending=False)==0\n",
    "# Merge start and end columns to form labels\n",
    "train_r1[\"task_position\"] = train_r1.apply(lambda row: \"position_start\" if row[\"activityStart\"] else (\"position_end\" if row[\"activityEnd\"] else 'position_between'), axis=1)\n",
    "\n",
    "train_r1 = train_r1.drop([\"activityStart\",'activityEnd'], axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-01T13:25:57.075440Z",
     "start_time": "2023-12-01T13:25:49.312133Z"
    }
   },
   "id": "ab9f276c3b9b9a66"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# Label Encode the Message Type\n",
    "messageTypeEncoder = LabelEncoder()\n",
    "messageTypeEncoder.fit(train_r1[\"MessageType\"].values)\n",
    "# Shift the labels by 1 to exclude 0 as label (we use it for padding starting sequences)\n",
    "train_r1[\"MessageType_labels\"] = messageTypeEncoder.transform(train_r1[\"MessageType\"]) + 1\n",
    "\n",
    "# One hot encode the Labels\n",
    "encoder = LabelEncoder()\n",
    "y = encoder.fit_transform(train_r1[\"task_position\"])\n",
    "dummy_y = to_categorical(y)\n",
    "\n",
    "\n",
    "\n",
    "# Todo build custom sliding window function forward + backward facing w. custom windowsize\n",
    "sequence_length = 20\n",
    "#labels = train_r1[\"MessageType_labels\"].rolling(window=windowsize).agg(list)\n",
    "sequences = sliding_window_view(train_r1[\"MessageType_labels\"], sequence_length)\n",
    "\n",
    "# pad first n-1 elements\n",
    "pad_top = [[0] * (sequence_length - 1 - i) + sequences[0, 0:i + 1].tolist() for i in range(sequence_length - 1)]\n",
    "\n",
    "X = np.insert(sequences,0, pad_top, axis=0).tolist()\n",
    "X = np.asarray(X).astype(np.float32)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-01T13:26:00.757553Z",
     "start_time": "2023-12-01T13:25:57.101637Z"
    }
   },
   "id": "1a54764c92edf68f"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "from keras.src.layers import LSTM\n",
    "from keras import Input\n",
    "\n",
    "\n",
    "def baseline_model():\n",
    "    embedding_dim = 150\n",
    "\n",
    "    vocab_size = len(messageTypeEncoder.classes_) + 1\n",
    "    model = Sequential([\n",
    "        Input(shape=(sequence_length,)),\n",
    "        Embedding(input_dim=vocab_size, output_dim=embedding_dim),\n",
    "        LSTM(units=64),\n",
    "        Dense(3, activation='softmax')])\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def stacked_LSTM(): \n",
    "    embedding_dim = 150\n",
    "    vocab_size = len(messageTypeEncoder.classes_) +1\n",
    "    model = Sequential([\n",
    "        Input(shape= sequence_length,),\n",
    "        Embedding(input_dim=vocab_size, output_dim=embedding_dim),\n",
    "        LSTM(64, activation='relu', return_sequences=True),\n",
    "        LSTM(64, activation='relu'),\n",
    "        Dense(3, activation='softmax')])\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['f1_score']) \n",
    "    return model\n",
    "\n",
    "def stacked_LSTM_weighted():\n",
    "    embedding_dim = 150\n",
    "    vocab_size = len(messageTypeEncoder.classes_) +1\n",
    "    model = Sequential([\n",
    "        Input(shape= sequence_length,),\n",
    "        Embedding(input_dim=vocab_size, output_dim=embedding_dim),\n",
    "        LSTM(64, activation='relu', return_sequences=True),\n",
    "        LSTM(64, activation='relu'),\n",
    "        Dense(3, activation='softmax')])\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['f1_score']) \n",
    "    return model\n",
    "\n",
    "\n",
    "    \n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-01T13:26:08.389581Z",
     "start_time": "2023-12-01T13:26:08.387038Z"
    }
   },
   "id": "3c7c726538cdfd44"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "x_train,x_test, y_train, y_test = train_test_split(X, dummy_y, test_size=0.2, shuffle=True, random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-01T13:26:33.129606Z",
     "start_time": "2023-12-01T13:26:32.893260Z"
    }
   },
   "id": "b7c182fe41031832"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "from scikeras.wrappers import KerasClassifier\n",
    "\n",
    "estimator = KerasClassifier(model=baseline_model, epochs=5, batch_size=1000, verbose=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-01T13:26:38.205956Z",
     "start_time": "2023-12-01T13:26:38.179594Z"
    }
   },
   "id": "9272fadb91b09b53"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-01 14:26:39.220819: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1 Pro\n",
      "2023-12-01 14:26:39.220877: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
      "2023-12-01 14:26:39.220887: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.33 GB\n",
      "2023-12-01 14:26:39.221150: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-12-01 14:26:39.221546: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-01 14:26:40.749515: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1285/1285\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m700s\u001B[0m 542ms/step - accuracy: 0.9945 - loss: 0.0254\n",
      "Epoch 2/5\n",
      "\u001B[1m1137/1285\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m1:17\u001B[0m 526ms/step - accuracy: 0.9988 - loss: 0.0035"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "estimator.fit(x_train, y_train)\n",
    "pred = estimator.predict(x_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-01T13:48:18.677853Z",
     "start_time": "2023-12-01T13:26:39.060425Z"
    }
   },
   "id": "702b2446085b2080"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "6d5b58b7d8ed4a66"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
